{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4032bb3",
   "metadata": {},
   "source": [
    "# 2025.06.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # If True, reading successful.\n",
    "# Make values environment variables temporarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "# key = os.getenv(\"HUGGINGFACE_API_KEYsssda\") # None\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438dabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.environ['HUGGINGFACE_API_KEY']\n",
    "# key = os.environ['HUGGINGFACE_API_KEYs'] # KeyError\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e108f3",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d62cba",
   "metadata": {},
   "source": [
    "### Naver Movie comments Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66567a",
   "metadata": {},
   "source": [
    "#### Huggingface Dataset Package\n",
    "\n",
    "* `pip install datasets`\n",
    "* https://huggingface.co/datasets\n",
    "* https://github.com/huggingface/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f0cea",
   "metadata": {},
   "source": [
    "#### Loading\n",
    "\n",
    "* `load_dataset('dastaset_name')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da10f66-32ba-462a-9fed-8908f61a1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6737e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "nsmc = load_dataset('e9t/nsmc', trust_remote_code = True)   # \n",
    "type(nsmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d3db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: actual dataset\n",
    "# DatasetDict: dictionary of dataset collection(train/valid/test)\n",
    "\n",
    "nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d84ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = nsmc['train']\n",
    "testset = nsmc.get('test')\n",
    "trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset['document'][:5], trainset['label'][:5], trainset['id'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7365f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trainset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.Dataset.from_extension(dataset_name)\n",
    "import datasets\n",
    "\n",
    "d = datasets.Dataset.from_pandas(df.head(100))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65d1f88",
   "metadata": {},
   "source": [
    "#### sampling\n",
    "\n",
    "* train: 10000\n",
    "\n",
    "* test: 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf99d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = trainset.shuffle().select(range(10000))\n",
    "sample_test = testset.shuffle().select(range(5000))\n",
    "# sample_test = testset.shuffle()[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_train, sample_test, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f6fef",
   "metadata": {},
   "source": [
    "#### Model, Tokenizer by AutoClass\n",
    "\n",
    "* https://huggingface.co/docs/transformers/model_doc/auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d7843-7dce-4586-a245-eecdb2da11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b132fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_id = 'beomi/kcbert-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beomi/kcbert-base -> Feature Extraction Model(not for Classification)\n",
    "\n",
    "# Message: You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "# L Untrained Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d27f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be678d1b",
   "metadata": {},
   "source": [
    "#### pytorch Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = sample_train['document'], sample_test['document'], sample_train['label'], sample_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c11433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "train_encoding = tokenizer(train_X, return_tensors = 'pt', padding = True) # padding standard?\n",
    "test_encoding = tokenizer(test_X, return_tensors = 'pt', padding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoding.keys()\n",
    "train_encoding['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8bb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NSMCDataset(Dataset):\n",
    "\n",
    "    def __init__(self, comments, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            comments(dict)\n",
    "            labels(list)\n",
    "        \"\"\"\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return(len(self.labels))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        to look up a single sequence in the batch\n",
    "        BERT Input Format -> (input_ids, token_type_ids, attention_mask)\n",
    "        Args(int):\n",
    "            idx(int)\n",
    "        Returns:\n",
    "            dict - input_ids, token_type_ids, attention_mask, label\n",
    "        \"\"\"\n",
    "        data = {key:val[idx] for key, val in self.comments.items()}\n",
    "        data['labels'] = torch.tensor([self.labels[idx]], dtype = torch.int64)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5adbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae259736",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = NSMCDataset(train_encoding, train_y) \n",
    "test_set = NSMCDataset(test_encoding, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd040fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1001ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3890fa0",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "* `TrainingArguments`, `Trainer` -> Convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1697f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "N_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir = 'models/nsmc',\n",
    "    num_train_epochs = N_EPOCHS,\n",
    "    per_device_train_batch_size = BATCH_SIZE,\n",
    "    per_device_eval_batch_size = BATCH_SIZE,\n",
    "\n",
    "    eval_strategy = 'epoch',  # 'no', 'step', 'epoch\n",
    "    save_strategy = 'epoch',\n",
    "\n",
    "    save_total_limit = 1,\n",
    "    load_best_model_at_end = True,   # Save and Load. subject to: eval_strategy = save_strategy\n",
    "\n",
    "    metric_for_best_model = 'eval_loss',\n",
    "    greater_is_better = False,      # like NMSE\n",
    "\n",
    "    report_to = 'none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Performance Evaluation\n",
    "acc_fn = evaluate.load('accuracy')   # f1, recall, precision, etc.\n",
    "acc_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.tensor([0, 1, 0, 1])\n",
    "ref = torch.tensor([0, 1, 0, 0])\n",
    "\n",
    "acc_fn.compute(predictions = pred, references = ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbdb47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    to get predicted values and evaluate performance while training\n",
    "    Args:\n",
    "        pred(EvalPrediction): Predicted values with ground truths\n",
    "    Returns:\n",
    "        dict - dict(score_name = score) \n",
    "    \"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(dim = -1)\n",
    "    metrics1 = evaluate.load(\"accuracy\")\n",
    "    metrics2 = evaluate.load(\"f1\")\n",
    "\n",
    "    acc = metrics1.compute(predictions = preds, references = labels)\n",
    "    f1 = metrics2.compute(predictions = preds, references = labels)\n",
    "    return {\"Accuracy\": acc, \"F1 Score\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a687d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = train_args,\n",
    "    train_dataset = train_set,   # torch.utils.data.Dataset   # trainer.train()\n",
    "    eval_dataset = testset,     # trainer.evaluate()\n",
    "    compute_metrics = compute_metrics   # default = loss function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332807a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8745097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save: tokenizer and model always same path\n",
    "save_path = 'models/nsmc'\n",
    "tokenizer.save_pretrained(save_path)\n",
    "model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac03ea2-296d-462f-9bbd-dd1df455007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "load_tokenizer = AutoTokenizer.from_pretrained(save_path)   # local path\n",
    "load_model = AutoModelForSequenceClassification.from_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd72f5b",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28324ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"이걸 영화라고 만든 거냐?\", \"아무 기대 없이 봤는데 재미있네.\", \"내가 감독이어도 이것보다 재미있게 만들겠다.\", \"시간이 어떻게 가는 줄 모르고 봤다.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task = 'text-classification', tokenizer = load_tokenizer, model = load_model)\n",
    "result = pipe(sentence)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'kcbert-nsmc-10000'\n",
    "load_tokenizer.push_to_hub(model_id)\n",
    "load_model.push_to_hub(model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
